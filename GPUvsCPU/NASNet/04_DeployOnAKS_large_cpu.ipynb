{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Web App on Azure Container Services (AKS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will set up an Azure Container Service which will be managed by Kubernetes. We will then take the Docker image we created earlier that contains our app and deploy it to the AKS cluster. Then, we will check everything is working by sending an image to it and getting it scored. \n",
    "\n",
    "The process is split into the following steps:\n",
    "- Define our resource names\n",
    "- Login to Azure\n",
    "- Create resource group and create AKS\n",
    "- Connect to AKS\n",
    "- Deploy our app\n",
    "- Tear it all down\n",
    "\n",
    "We assume that this notebook is running on Linux and Azure CLI is installed before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the various name definitions for the resources needed to setup AKS as well as the name of the Docker image we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please modify the below as you see fit\n",
    "resource_group = \"<RESOURCE_GROUP>\" \n",
    "aks_name = \"<AKS_CLUSTER_NAME>\"\n",
    "location = \"eastus\"\n",
    "\n",
    "image_name = '<YOUR_DOCKER_IMAGE>' # 'fboylu/kerastf-gpu' Feel free to use this image if you want to \n",
    "                                   # skip creating your own container\n",
    "selected_subscription = \"'<YOUR_SUBSCRIPTION>'\" # If you have multiple subscriptions select \n",
    "                                                # the subscription you want to use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group = \"fbakscpurg\" # Feel free to modify these\n",
    "aks_name = \"fbAKSClustercpu\"\n",
    "location = \"eastus\"\n",
    "\n",
    "image_name = \"fboylu/kerasnasl-cpu\" \n",
    "selected_subscription = \"'Team Danielle Internal'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure account login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below will initiate a login to your Azure account. It will pop up with an url to go to where you will enter a one off code and log into your Azure account using your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FYRX4L92B to authenticate.\u001b[0m\n",
      "CloudName    IsDefault    Name                           State    TenantId\n",
      "-----------  -----------  -----------------------------  -------  ------------------------------------\n",
      "AzureCloud   False        Boston DS Dev                  Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Internal Consumption           Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   True         Team Danielle Internal         Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Core-ES-BLD                    Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Boston Engineering             Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        ADLTrainingMS                  Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Ads Eng Big Data Subscription  Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Data Wrangling Preview         Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        R portal - Production          Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Project Vienna Demo 1          Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Solution Template Testing      Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   False        Team Ilan                      Enabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az account set --subscription $selected_subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"environmentName\": \"AzureCloud\",\r\n",
      "  \"id\": \"edf507a2-6235-46c5-b560-fd463ba2e771\",\r\n",
      "  \"isDefault\": true,\r\n",
      "  \"name\": \"Team Danielle Internal\",\r\n",
      "  \"state\": \"Enabled\",\r\n",
      "  \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",\r\n",
      "  \"user\": {\r\n",
      "    \"name\": \"fboylu@microsoft.com\",\r\n",
      "    \"type\": \"user\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az account show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to register the container service resources on your subscription if you haven't already done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az provider register -n Microsoft.ContainerService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az provider show -n Microsoft.ContainerService"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create resources and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create resource group and AKS cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure encourages the use of groups to organize all the Azure components you deploy. That way it is easier to find them but also we can delete a number of resources simply by deleting the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fbakscpurg\",\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"managedBy\": null,\r\n",
      "  \"name\": \"fbakscpurg\",\r\n",
      "  \"properties\": {\r\n",
      "    \"provisioningState\": \"Succeeded\"\r\n",
      "  },\r\n",
      "  \"tags\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az group create --name $resource_group --location $location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create the AKS cluster in the resource group we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"count\": 5,\n",
      "      \"dnsPrefix\": null,\n",
      "      \"fqdn\": null,\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"osDiskSizeGb\": null,\n",
      "      \"osType\": \"Linux\",\n",
      "      \"ports\": null,\n",
      "      \"storageProfile\": \"ManagedDisks\",\n",
      "      \"vmSize\": \"Standard_D4_v2\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"dnsPrefix\": \"fbAKSClust-fbakscpurg-edf507\",\n",
      "  \"fqdn\": \"fbaksclust-fbakscpurg-edf507-74a0b7ae.hcp.eastus.azmk8s.io\",\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/fbakscpurg/providers/Microsoft.ContainerService/managedClusters/fbAKSClustercpu\",\n",
      "  \"kubernetesVersion\": \"1.9.6\",\n",
      "  \"linuxProfile\": {\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDTZYQFHNstYCR25qtvMrC6baTMS6TobaIRbgd0xOoafDy+2uBk0DMJuhGWoOcrsCnvadp5k/0K8qBRysyhlQGWb6+r8fBunThy+zpTKqdh3W8Q1y5UtKnGwwU1cqGXDOPUIXJYNPJqUKV829+MOrZjUynhHgSzDbY2ncGyoT+Farsvm01aGEdDapa+XRl4JAwtN1bb9q+Ii5y+MkpIOhLRMwATl05eNfAHmYQWtaIJZZJOHMNPswlBmLs293Wsj11vYh6/yo9S4ToEsc9Pbl5Zn6OFIu7jfzN2bM8cA3+8pru9WSthrxjJvPn8i4uTYozOdNIi09ArQ4lRT9t6rsMz\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"fbAKSClustercpu\",\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"fbakscpurg\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"clientId\": \"eeba3bfe-45f9-42de-9bdb-54416b67382d\",\n",
      "    \"keyVaultSecretRef\": null,\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\"\n",
      "}\n",
      "\u001b[0mCPU times: user 10.3 s, sys: 1.78 s, total: 12.1 s\n",
      "Wall time: 13min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!az aks create --resource-group $resource_group --name $aks_name --node-count 5 --generate-ssh-keys -s Standard_D4_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !az aks scale --resource-group=$resource_group --name=$aks_name --node-count 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name             Location    ResourceGroup    KubernetesVersion    ProvisioningState    Fqdn\r\n",
      "---------------  ----------  ---------------  -------------------  -------------------  ----------------------------------------------------------\r\n",
      "dangdevopsclstr  eastus      dangdevops       1.9.6                Succeeded            devops-3b040ce9.hcp.eastus.azmk8s.io\r\n",
      "ddaks            eastus      ddaksdeploy      1.8.11               Failed               ddaks-ddaksdeploy-edf507-eefe283f.hcp.eastus.azmk8s.io\r\n",
      "fbAKSClustercpu  eastus      fbakscpurg       1.9.6                Succeeded            fbaksclust-fbakscpurg-edf507-74a0b7ae.hcp.eastus.azmk8s.io\r\n",
      "fbAKSClustergpu  eastus      fbaksrg          1.9.6                Succeeded            fbaksclust-fbaksrg-edf507-e12d7f40.hcp.eastus.azmk8s.io\r\n",
      "msaksgpu         eastus      msaksrg          1.9.6                Succeeded            msaksgpu-msaksrg-edf507-0eeb29a6.hcp.eastus.azmk8s.io\r\n"
     ]
    }
   ],
   "source": [
    "!az aks list -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install kubectl CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the Kubernetes cluster, we will use kubectl, the Kubernetes command-line client. To install, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDownloading client to /usr/local/bin/kubectl from https://storage.googleapis.com/kubernetes-release/release/v1.10.4/bin/linux/amd64/kubectl\u001b[0m\n",
      "\u001b[33mPlease ensure that /usr/local/bin is in your search PATH, so the `kubectl` command can be found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo -i az aks install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AKS cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure kubectl to connect to the Kubernetes cluster, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged \"fbAKSClustercpu\" as current context in /home/fboylu/.kube/config\r\n"
     ]
    }
   ],
   "source": [
    "!az aks get-credentials --resource-group $resource_group --name $aks_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify connection by listing the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       STATUS    ROLES     AGE       VERSION\r\n",
      "aks-nodepool1-13347348-0   Ready     agent     6d        v1.9.6\r\n",
      "aks-nodepool1-13347348-1   Ready     agent     6d        v1.9.6\r\n",
      "aks-nodepool1-13347348-2   Ready     agent     6d        v1.9.6\r\n",
      "aks-nodepool1-13347348-3   Ready     agent     6d        v1.9.6\r\n",
      "aks-nodepool1-13347348-4   Ready     agent     6d        v1.9.6\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the pods on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "kube-system   azureproxy-79c5db744-j5hj4              1/1       Running   3          6d\r\n",
      "kube-system   heapster-55f855b47-bs86x                2/2       Running   0          6d\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-96dfd           3/3       Running   0          6d\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-fm7v2           3/3       Running   0          6d\r\n",
      "kube-system   kube-proxy-225hz                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-g5x5p                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-hw7fk                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-ttnsh                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-tvnpv                        1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-278jk                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-bhvsk                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-chkj2                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-k7fs6                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-mg5cj                 1/1       Running   0          6d\r\n",
      "kube-system   kubernetes-dashboard-546f987686-rznkm   1/1       Running   2          6d\r\n",
      "kube-system   tunnelfront-5fcfb8fb44-ht5r8            1/1       Running   0          6d\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define our Kubernetes manifest file for our service and load balancer. Note that we have to specify the volume mounts to the drivers that are located on the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_template = {\n",
    "  \"apiVersion\": \"apps/v1beta1\",\n",
    "  \"kind\": \"Deployment\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"replicas\":2,\n",
    "      \"template\":{\n",
    "          \"metadata\":{\n",
    "              \"labels\":{\n",
    "                  \"app\":\"azure-dl\"\n",
    "              }\n",
    "          },\n",
    "          \"spec\":{\n",
    "              \"containers\":[\n",
    "                  {\n",
    "                      \"name\": \"azure-dl\",\n",
    "                      \"image\": \"fboylu/kerasnasl-cpu\",\n",
    "\n",
    "                      \"ports\":[\n",
    "                          {\n",
    "                              \"containerPort\":80,\n",
    "                              \"name\":\"model\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"resources\":{\n",
    "                           \"requests\":{\n",
    "                               \"cpu\": 1\n",
    "                           },\n",
    "                           \"limits\":{\n",
    "                               \"cpu\": 1.25\n",
    "                           }\n",
    "                       }  \n",
    "                  }\n",
    "              ]\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "service_temp = {\n",
    "  \"apiVersion\": \"v1\",\n",
    "  \"kind\": \"Service\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"type\": \"LoadBalancer\",\n",
    "      \"ports\":[\n",
    "          {\n",
    "              \"port\":80\n",
    "          }\n",
    "      ],\n",
    "      \"selector\":{\n",
    "            \"app\":\"azure-dl\"\n",
    "      }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write_json_to_file(json_dict, filename, mode='w'):\n",
    "    with open(filename, mode) as outfile:\n",
    "        json.dump(json_dict, outfile, indent=4, sort_keys=True)\n",
    "        outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_to_file(app_template, 'az-dl.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_to_file(service_temp, 'az-dl.json', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the manifest created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"apiVersion\": \"apps/v1beta1\",\r\n",
      "    \"kind\": \"Deployment\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"replicas\": 2,\r\n",
      "        \"template\": {\r\n",
      "            \"metadata\": {\r\n",
      "                \"labels\": {\r\n",
      "                    \"app\": \"azure-dl\"\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"spec\": {\r\n",
      "                \"containers\": [\r\n",
      "                    {\r\n",
      "                        \"image\": \"fboylu/kerasnasl-cpu\",\r\n",
      "                        \"name\": \"azure-dl\",\r\n",
      "                        \"ports\": [\r\n",
      "                            {\r\n",
      "                                \"containerPort\": 80,\r\n",
      "                                \"name\": \"model\"\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"resources\": {\r\n",
      "                            \"limits\": {\r\n",
      "                                \"cpu\": 1.25\r\n",
      "                            },\r\n",
      "                            \"requests\": {\r\n",
      "                                \"cpu\": 1\r\n",
      "                            }\r\n",
      "                        }\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        }\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n",
      "{\r\n",
      "    \"apiVersion\": \"v1\",\r\n",
      "    \"kind\": \"Service\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"ports\": [\r\n",
      "            {\r\n",
      "                \"port\": 80\r\n",
      "            }\r\n",
      "        ],\r\n",
      "        \"selector\": {\r\n",
      "            \"app\": \"azure-dl\"\r\n",
      "        },\r\n",
      "        \"type\": \"LoadBalancer\"\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat az-dl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use kubectl create command to deploy our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"azure-dl\" created\n",
      "service \"azure-dl\" created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f az-dl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the pod is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "default       azure-dl-7fdd7b85d5-b8lgp               1/1       Running   0          11m\r\n",
      "default       azure-dl-7fdd7b85d5-lk2m7               1/1       Running   0          11m\r\n",
      "kube-system   azureproxy-79c5db744-j5hj4              1/1       Running   3          6d\r\n",
      "kube-system   heapster-55f855b47-bs86x                2/2       Running   0          6d\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-96dfd           3/3       Running   0          6d\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-fm7v2           3/3       Running   0          6d\r\n",
      "kube-system   kube-proxy-225hz                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-g5x5p                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-hw7fk                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-ttnsh                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-tvnpv                        1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-278jk                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-bhvsk                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-chkj2                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-k7fs6                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-mg5cj                 1/1       Running   0          6d\r\n",
      "kube-system   kubernetes-dashboard-546f987686-rznkm   1/1       Running   2          6d\r\n",
      "kube-system   tunnelfront-5fcfb8fb44-ht5r8            1/1       Running   0          6d\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything goes wrong you can use the commands below to observe the events on the node as well as review the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST SEEN   FIRST SEEN   COUNT     NAME                                         KIND         SUBOBJECT                   TYPE      REASON                       SOURCE                              MESSAGE\r\n",
      "13m         13m          1         azure-dl-65485c56d8-2pl5h.153858c2a71db95e   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-1   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-4klvn.153858c2a4284308   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-4   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-5fkw5.153858c2aadffb8b   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-0   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-5hzx8.153858c2a7e9ad86   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-2   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-6pmc6.153858c2a387e2ff   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-3   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-79lhb.153858c2a65e4653   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-3   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-8j8wb.153858c2a53531f3   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-1   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-8s487.153858c2a8147331   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-0   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-8xphs.153858c2a245fdd2   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-4   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-9tx8f.153858c2a65e0a2a   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-3   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-9wpp6.153858c2a661183c   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-3   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-c56j6.153858c2a250411a   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-2   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-cg97m.153858c2a54b8993   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-0   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-cg97m.153858c34feb101d   Pod                                      Warning   FailedSync                   kubelet, aks-nodepool1-13347348-0   error determining status: rpc error: code = Unknown desc = Error: No such container: 021f9de58a4c91010fd010894257982c2a66270ec7753e1599da295363e9fe0d\r\n",
      "13m         13m          1         azure-dl-65485c56d8-cq8rq.153858c2a7ffd4d9   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-1   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-crtk4.153858c2a074f4de   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-4   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-ctbbk.153858c2a6f7ed92   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-2   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-d8jwc.153858c2a6f7e752   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-2   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-dd96n.153858c2a45290df   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-1   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-dkb2h.153858c2a38691df   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-3   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-fcsqp.153858c2a71c7073   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-1   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-hgdsl.153858c2a99d4501   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-0   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-hzpnc.153858c2a54b9b8b   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-0   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-nlsvm.153858c2a6f6335d   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-2   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-nmq8x.153858c2a6fd6dd7   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-2   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-p9fcc.153858c2a66303aa   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-0   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-rl85s.153858c2a3868ccb   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-3   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-rmj5l.153858c2a5469357   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-1   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-rzjnx.153858c2a6ed3079   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-4   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-s9wxs.153858c2a7e106e6   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-4   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-tqk2d.153858c2a54b8ea7   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-0   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-vbvdn.153858c2a451f759   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-1   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-xqw6f.153858c2a9ceb2f5   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-4   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-z7f7r.153858c2a24f5527   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-2   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-zhbmq.153858c2a65e0a8e   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-3   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8-zjqn2.153858c2a330d637   Pod          spec.containers{azure-dl}   Normal    Killing                      kubelet, aks-nodepool1-13347348-4   Killing container with id docker://azure-dl:Need to kill Pod\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03d0c23cf         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-2pl5h\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03d0d8f7b         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-fcsqp\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03d0ddba6         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-vbvdn\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03d0e1ed6         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-crtk4\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03da6ce92         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-s9wxs\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03db77c16         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-d8jwc\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03db7a005         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-6pmc6\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03db82471         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-rzjnx\r\n",
      "13m         13m          1         azure-dl-65485c56d8.153858c03dbcd218         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               Deleted pod: azure-dl-65485c56d8-cg97m\r\n",
      "13m         13m          16        azure-dl-65485c56d8.153858c06cca6fde         ReplicaSet                               Normal    SuccessfulDelete             replicaset-controller               (combined from similar events): Deleted pod: azure-dl-65485c56d8-5fkw5\r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5-b8lgp.153858df0cdee74f   Pod                                      Normal    Scheduled                    default-scheduler                   Successfully assigned azure-dl-7fdd7b85d5-b8lgp to aks-nodepool1-13347348-4\r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5-b8lgp.153858df1bb57f9c   Pod                                      Normal    SuccessfulMountVolume        kubelet, aks-nodepool1-13347348-4   MountVolume.SetUp succeeded for volume \"default-token-lls54\" \r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5-b8lgp.153858df4f97162a   Pod          spec.containers{azure-dl}   Normal    Pulling                      kubelet, aks-nodepool1-13347348-4   pulling image \"fboylu/kerasnasl-cpu\"\r\n",
      "9m          9m           1         azure-dl-7fdd7b85d5-b8lgp.153858fc2482b479   Pod          spec.containers{azure-dl}   Normal    Pulled                       kubelet, aks-nodepool1-13347348-4   Successfully pulled image \"fboylu/kerasnasl-cpu\"\r\n",
      "9m          9m           1         azure-dl-7fdd7b85d5-b8lgp.153858fc351dc153   Pod          spec.containers{azure-dl}   Normal    Created                      kubelet, aks-nodepool1-13347348-4   Created container\r\n",
      "9m          9m           1         azure-dl-7fdd7b85d5-b8lgp.153858fc424f6f39   Pod          spec.containers{azure-dl}   Normal    Started                      kubelet, aks-nodepool1-13347348-4   Started container\r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5-lk2m7.153858df0cdb9422   Pod                                      Normal    Scheduled                    default-scheduler                   Successfully assigned azure-dl-7fdd7b85d5-lk2m7 to aks-nodepool1-13347348-3\r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5-lk2m7.153858df1cb773c1   Pod                                      Normal    SuccessfulMountVolume        kubelet, aks-nodepool1-13347348-3   MountVolume.SetUp succeeded for volume \"default-token-lls54\" \r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5-lk2m7.153858df52edcc14   Pod          spec.containers{azure-dl}   Normal    Pulling                      kubelet, aks-nodepool1-13347348-3   pulling image \"fboylu/kerasnasl-cpu\"\r\n",
      "9m          9m           1         azure-dl-7fdd7b85d5-lk2m7.153858fe51d7489f   Pod          spec.containers{azure-dl}   Normal    Pulled                       kubelet, aks-nodepool1-13347348-3   Successfully pulled image \"fboylu/kerasnasl-cpu\"\r\n",
      "9m          9m           1         azure-dl-7fdd7b85d5-lk2m7.153858fe619567ee   Pod          spec.containers{azure-dl}   Normal    Created                      kubelet, aks-nodepool1-13347348-3   Created container\r\n",
      "9m          9m           1         azure-dl-7fdd7b85d5-lk2m7.153858fe6fac2bda   Pod          spec.containers{azure-dl}   Normal    Started                      kubelet, aks-nodepool1-13347348-3   Started container\r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5.153858df0c76d6ed         ReplicaSet                               Normal    SuccessfulCreate             replicaset-controller               Created pod: azure-dl-7fdd7b85d5-lk2m7\r\n",
      "11m         11m          1         azure-dl-7fdd7b85d5.153858df0cb1d5fd         ReplicaSet                               Normal    SuccessfulCreate             replicaset-controller               Created pod: azure-dl-7fdd7b85d5-b8lgp\r\n",
      "13m         13m          1         azure-dl.153858c03b3134b5                    Deployment                               Normal    ScalingReplicaSet            deployment-controller               Scaled down replica set azure-dl-65485c56d8 to 0\r\n",
      "13m         13m          1         azure-dl.153858c08df552dd                    Service                                  Normal    DeletingLoadBalancer         service-controller                  Deleting load balancer\r\n",
      "11m         11m          1         azure-dl.153858df0bbe5c8e                    Deployment                               Normal    ScalingReplicaSet            deployment-controller               Scaled up replica set azure-dl-7fdd7b85d5 to 2\r\n",
      "10m         10m          1         azure-dl.153858e4800578af                    Service                                  Normal    DeletedLoadBalancer          service-controller                  Deleted load balancer\r\n",
      "5m          10m          4         azure-dl.153858e4800710e3                    Service                                  Normal    EnsuringLoadBalancer         service-controller                  Ensuring load balancer\r\n",
      "8m          8m           1         azure-dl.15385908d4e3521e                    Service                                  Warning   CreatingLoadBalancerFailed   service-controller                  Error creating load balancer (will retry): failed to ensure load balancer for service default/azure-dl: [ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-2 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\", ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-3 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\", ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-4 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\", ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-1 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\"]\r\n",
      "7m          7m           1         azure-dl.15385915e115b449                    Service                                  Warning   CreatingLoadBalancerFailed   service-controller                  Error creating load balancer (will retry): failed to ensure load balancer for service default/azure-dl: [ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-2 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\", ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-4 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\", ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-1 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\"]\r\n",
      "5m          5m           1         azure-dl.15385928fd48a50b                    Service                                  Warning   CreatingLoadBalancerFailed   service-controller                  Error creating load balancer (will retry): failed to ensure load balancer for service default/azure-dl: ensure(default/azure-dl): lb(kubernetes) - failed to ensure host in pool: \"network.InterfacesClient#CreateOrUpdate: Failure responding to request: StatusCode=429 -- Original Error: autorest/azure: Service returned an error. Status=429 Code=\\\"RetryableError\\\" Message=\\\"A retryable error occurred.\\\" Details=[{\\\"code\\\":\\\"ReferencedResourceNotProvisioned\\\",\\\"message\\\":\\\"Cannot proceed with operation because resource /subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/MC_fbakscpurg_fbAKSClustercpu_eastus/providers/Microsoft.Compute/availabilitySets/nodepool1-availabilitySet-13347348 used by resource aks-nodepool1-13347348-nic-2 is not in Succeeded state. Resource is in Updating state and the last operation that updated/is updating the resource is InternalOperation.\\\"}]\"\r\n",
      "4m          4m           1         azure-dl.1538593a1ae00c24                    Service                                  Normal    EnsuredLoadBalancer          service-controller                  Ensured load balancer\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the logs for the application pod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_json = !kubectl get pods -o json\n",
    "pod_dict = json.loads(''.join(pod_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-15 13:38:34,051 CRIT Supervisor running as root (no user in config file)\r\n",
      "2018-06-15 13:38:34,055 INFO supervisord started with pid 1\r\n",
      "2018-06-15 13:38:35,057 INFO spawned: 'program_exit' with pid 11\r\n",
      "2018-06-15 13:38:35,059 INFO spawned: 'nginx' with pid 12\r\n",
      "2018-06-15 13:38:35,061 INFO spawned: 'gunicorn' with pid 13\r\n",
      "2018-06-15 13:38:36,175 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\r\n",
      "2018-06-15 13:38:36.894701: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n",
      "2018-06-15 13:38:40,899 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\r\n",
      "2018-06-15 13:38:55,920 INFO success: gunicorn entered RUNNING state, process has stayed up for > than 20 seconds (startsecs)\r\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-large.h5\r\n",
      "\r\n",
      "     8192/359746192 [..............................] - ETA: 1:28\r\n",
      "   319488/359746192 [..............................] - ETA: 1:27\r\n",
      "  1392640/359746192 [..............................] - ETA: 33s \r\n",
      "  3899392/359746192 [..............................] - ETA: 16s\r\n",
      "  8355840/359746192 [..............................] - ETA: 9s \r\n",
      " 14442496/359746192 [>.............................] - ETA: 6s\r\n",
      " 20971520/359746192 [>.............................] - ETA: 5s\r\n",
      " 28344320/359746192 [=>............................] - ETA: 4s\r\n",
      " 35545088/359746192 [=>............................] - ETA: 3s\r\n",
      " 43057152/359746192 [==>...........................] - ETA: 3s\r\n",
      " 49840128/359746192 [===>..........................] - ETA: 3s\r\n",
      " 56926208/359746192 [===>..........................] - ETA: 3s\r\n",
      " 64495616/359746192 [====>.........................] - ETA: 2s\r\n",
      " 71663616/359746192 [====>.........................] - ETA: 2s\r\n",
      " 78995456/359746192 [=====>........................] - ETA: 2s\r\n",
      " 86171648/359746192 [======>.......................] - ETA: 2s\r\n",
      " 93372416/359746192 [======>.......................] - ETA: 2s\r\n",
      "100720640/359746192 [=======>......................] - ETA: 2s\r\n",
      "107823104/359746192 [=======>......................] - ETA: 2s\r\n",
      "113803264/359746192 [========>.....................] - ETA: 2s\r\n",
      "118554624/359746192 [========>.....................] - ETA: 2s\r\n",
      "123740160/359746192 [=========>....................] - ETA: 2s\r\n",
      "128745472/359746192 [=========>....................] - ETA: 2s\r\n",
      "133750784/359746192 [==========>...................] - ETA: 1s\r\n",
      "138780672/359746192 [==========>...................] - ETA: 1s\r\n",
      "143728640/359746192 [==========>...................] - ETA: 1s\r\n",
      "148520960/359746192 [===========>..................] - ETA: 1s\r\n",
      "155934720/359746192 [============>.................] - ETA: 1s\r\n",
      "161619968/359746192 [============>.................] - ETA: 1s\r\n",
      "166633472/359746192 [============>.................] - ETA: 1s\r\n",
      "171704320/359746192 [=============>................] - ETA: 1s\r\n",
      "176644096/359746192 [=============>................] - ETA: 1s\r\n",
      "181641216/359746192 [==============>...............] - ETA: 1s\r\n",
      "186671104/359746192 [==============>...............] - ETA: 1s\r\n",
      "191643648/359746192 [==============>...............] - ETA: 1s\r\n",
      "196616192/359746192 [===============>..............] - ETA: 1s\r\n",
      "201703424/359746192 [===============>..............] - ETA: 1s\r\n",
      "206716928/359746192 [================>.............] - ETA: 1s\r\n",
      "211828736/359746192 [================>.............] - ETA: 1s\r\n",
      "216834048/359746192 [=================>............] - ETA: 1s\r\n",
      "221773824/359746192 [=================>............] - ETA: 1s\r\n",
      "223608832/359746192 [=================>............] - ETA: 1s\r\n",
      "230957056/359746192 [==================>...........] - ETA: 1s\r\n",
      "236847104/359746192 [==================>...........] - ETA: 1s\r\n",
      "241901568/359746192 [===================>..........] - ETA: 1s\r\n",
      "246923264/359746192 [===================>..........] - ETA: 1s\r\n",
      "251936768/359746192 [====================>.........] - ETA: 1s\r\n",
      "256917504/359746192 [====================>.........] - ETA: 0s\r\n",
      "261939200/359746192 [====================>.........] - ETA: 0s\r\n",
      "266936320/359746192 [=====================>........] - ETA: 0s\r\n",
      "271949824/359746192 [=====================>........] - ETA: 0s\r\n",
      "276996096/359746192 [======================>.......] - ETA: 0s\r\n",
      "282042368/359746192 [======================>.......] - ETA: 0s\r\n",
      "287096832/359746192 [======================>.......] - ETA: 0s\r\n",
      "291872768/359746192 [=======================>......] - ETA: 0s\r\n",
      "297017344/359746192 [=======================>......] - ETA: 0s\r\n",
      "300900352/359746192 [========================>.....] - ETA: 0s\r\n",
      "307904512/359746192 [========================>.....] - ETA: 0s\r\n",
      "313417728/359746192 [=========================>....] - ETA: 0s\r\n",
      "319193088/359746192 [=========================>....] - ETA: 0s\r\n",
      "324239360/359746192 [==========================>...] - ETA: 0s\r\n",
      "329203712/359746192 [==========================>...] - ETA: 0s\r\n",
      "334168064/359746192 [==========================>...] - ETA: 0s\r\n",
      "339263488/359746192 [===========================>..] - ETA: 0s\r\n",
      "343351296/359746192 [===========================>..] - ETA: 0s\r\n",
      "348733440/359746192 [============================>.] - ETA: 0s\r\n",
      "354263040/359746192 [============================>.] - ETA: 0s\r\n",
      "359161856/359746192 [============================>.] - ETA: 0s\r\n",
      "359751680/359746192 [==============================] - 3s 0us/step\r\n",
      "{\"timestamp\": \"2018-06-15T13:39:37.707144Z\", \"logger\": \"model_driver\", \"tags\": [], \"path\": \"/code/driver.py\", \"level\": \"INFO\", \"host\": \"azure-dl-7fdd7b85d5-b8lgp\", \"message\": \"Model loading time: 60841.68 ms\", \"stack_info\": null}\r\n",
      "Initialising\r\n",
      "{\"timestamp\": \"2018-06-15T13:39:37.715838Z\", \"logger\": \"werkzeug\", \"tags\": [], \"path\": \"/opt/conda/envs/py3.5/lib/python3.5/site-packages/werkzeug/_internal.py\", \"level\": \"INFO\", \"host\": \"azure-dl-7fdd7b85d5-b8lgp\", \"msg\": \" * Running on %s://%s:%d/ %s\", \"message\": \" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\", \"stack_info\": null}\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs {pod_dict['items'][0]['metadata']['name']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\r\n",
      "azure-dl   2         2         2            2           13m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can take a few minutes for the service to populate the EXTERNAL-IP field below. This will be the IP you use to call the service. You can also specify an IP to use, please see the AKS documentation for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE\r\n",
      "azure-dl   LoadBalancer   10.0.157.201   40.117.209.80   80:32576/TCP   44m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service azure-dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will [test our web application deployed on AKS](05_TestWebApp.ipynb). Once, we are done with all the notebooks of the tutorial, below instructions can be used to delete the cluster and free resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!az aks scale --resource-group=$resource_group --name=$aks_name --node-count 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kubectl describe nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions \"azure-dl\" scaled\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl scale --current-replicas=30 --replicas=35 deployment/azure-dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "default       azure-dl-7fdd7b85d5-22996               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-4p5m9               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-6l7rp               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-7w26q               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-8n6vm               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-98rvv               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-9dss5               1/1       Running   0          8m\r\n",
      "default       azure-dl-7fdd7b85d5-9k5zp               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-9zd2f               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-b8lgp               1/1       Running   0          51m\r\n",
      "default       azure-dl-7fdd7b85d5-c4hqc               1/1       Running   0          8m\r\n",
      "default       azure-dl-7fdd7b85d5-g95x2               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-gtsqg               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-hrlmf               1/1       Running   0          8m\r\n",
      "default       azure-dl-7fdd7b85d5-lf9gc               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-lk2m7               1/1       Running   0          51m\r\n",
      "default       azure-dl-7fdd7b85d5-mdr95               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-mj87w               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-nh4km               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-nn2zm               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-nxcbl               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-pvkns               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-r4d9z               1/1       Running   0          8m\r\n",
      "default       azure-dl-7fdd7b85d5-r75kq               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-s2tph               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-v2xcm               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-vkjgm               1/1       Running   0          8m\r\n",
      "default       azure-dl-7fdd7b85d5-vrkhq               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-vwgcq               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-vzg75               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-wj99t               1/1       Running   0          22m\r\n",
      "default       azure-dl-7fdd7b85d5-wrkjm               1/1       Running   0          26m\r\n",
      "default       azure-dl-7fdd7b85d5-xdnzq               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-xv6nw               1/1       Running   0          32m\r\n",
      "default       azure-dl-7fdd7b85d5-zfqrq               1/1       Running   0          26m\r\n",
      "kube-system   azureproxy-79c5db744-j5hj4              1/1       Running   3          6d\r\n",
      "kube-system   heapster-55f855b47-bs86x                2/2       Running   0          6d\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-96dfd           3/3       Running   0          6d\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-fm7v2           3/3       Running   0          6d\r\n",
      "kube-system   kube-proxy-225hz                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-g5x5p                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-hw7fk                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-ttnsh                        1/1       Running   0          6d\r\n",
      "kube-system   kube-proxy-tvnpv                        1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-278jk                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-bhvsk                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-chkj2                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-k7fs6                 1/1       Running   0          6d\r\n",
      "kube-system   kube-svc-redirect-mg5cj                 1/1       Running   0          6d\r\n",
      "kube-system   kubernetes-dashboard-546f987686-rznkm   1/1       Running   2          6d\r\n",
      "kube-system   tunnelfront-5fcfb8fb44-ht5r8            1/1       Running   0          6d\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\r\n",
      "azure-dl   35        35        35           35          51m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-15 13:38:43,377 CRIT Supervisor running as root (no user in config file)\r\n",
      "2018-06-15 13:38:43,379 INFO supervisord started with pid 1\r\n",
      "2018-06-15 13:38:44,382 INFO spawned: 'program_exit' with pid 10\r\n",
      "2018-06-15 13:38:44,384 INFO spawned: 'nginx' with pid 11\r\n",
      "2018-06-15 13:38:44,385 INFO spawned: 'gunicorn' with pid 12\r\n",
      "2018-06-15 13:38:45,425 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\r\n",
      "2018-06-15 13:38:45.976123: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n",
      "2018-06-15 13:38:49,982 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\r\n",
      "2018-06-15 13:39:04,999 INFO success: gunicorn entered RUNNING state, process has stayed up for > than 20 seconds (startsecs)\r\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.8/NASNet-large.h5\r\n",
      "\r\n",
      "     8192/359746192 [..............................] - ETA: 1:01\r\n",
      "   507904/359746192 [..............................] - ETA: 1:02\r\n",
      "  1884160/359746192 [..............................] - ETA: 26s \r\n",
      "  4218880/359746192 [..............................] - ETA: 15s\r\n",
      "  8609792/359746192 [..............................] - ETA: 9s \r\n",
      " 13664256/359746192 [>.............................] - ETA: 7s\r\n",
      " 19365888/359746192 [>.............................] - ETA: 5s\r\n",
      " 25337856/359746192 [=>............................] - ETA: 5s\r\n",
      " 31309824/359746192 [=>............................] - ETA: 4s\r\n",
      " 36610048/359746192 [==>...........................] - ETA: 4s\r\n",
      " 42369024/359746192 [==>...........................] - ETA: 4s\r\n",
      " 47980544/359746192 [===>..........................] - ETA: 3s\r\n",
      " 53551104/359746192 [===>..........................] - ETA: 3s\r\n",
      " 58687488/359746192 [===>..........................] - ETA: 3s\r\n",
      " 63766528/359746192 [====>.........................] - ETA: 3s\r\n",
      " 69099520/359746192 [====>.........................] - ETA: 3s\r\n",
      " 74227712/359746192 [=====>........................] - ETA: 3s\r\n",
      " 80191488/359746192 [=====>........................] - ETA: 3s\r\n",
      " 86335488/359746192 [======>.......................] - ETA: 2s\r\n",
      " 91766784/359746192 [======>.......................] - ETA: 2s\r\n",
      " 97779712/359746192 [=======>......................] - ETA: 2s\r\n",
      "103907328/359746192 [=======>......................] - ETA: 2s\r\n",
      "109469696/359746192 [========>.....................] - ETA: 2s\r\n",
      "115433472/359746192 [========>.....................] - ETA: 2s\r\n",
      "121520128/359746192 [=========>....................] - ETA: 2s\r\n",
      "127746048/359746192 [=========>....................] - ETA: 2s\r\n",
      "133120000/359746192 [==========>...................] - ETA: 2s\r\n",
      "138977280/359746192 [==========>...................] - ETA: 2s\r\n",
      "144998400/359746192 [===========>..................] - ETA: 2s\r\n",
      "150528000/359746192 [===========>..................] - ETA: 2s\r\n",
      "155615232/359746192 [===========>..................] - ETA: 2s\r\n",
      "161660928/359746192 [============>.................] - ETA: 1s\r\n",
      "167723008/359746192 [============>.................] - ETA: 1s\r\n",
      "174104576/359746192 [=============>................] - ETA: 1s\r\n",
      "180035584/359746192 [==============>...............] - ETA: 1s\r\n",
      "186122240/359746192 [==============>...............] - ETA: 1s\r\n",
      "192241664/359746192 [===============>..............] - ETA: 1s\r\n",
      "198246400/359746192 [===============>..............] - ETA: 1s\r\n",
      "203292672/359746192 [===============>..............] - ETA: 1s\r\n",
      "208896000/359746192 [================>.............] - ETA: 1s\r\n",
      "214532096/359746192 [================>.............] - ETA: 1s\r\n",
      "219701248/359746192 [=================>............] - ETA: 1s\r\n",
      "224993280/359746192 [=================>............] - ETA: 1s\r\n",
      "230023168/359746192 [==================>...........] - ETA: 1s\r\n",
      "234405888/359746192 [==================>...........] - ETA: 1s\r\n",
      "239681536/359746192 [==================>...........] - ETA: 1s\r\n",
      "244629504/359746192 [===================>..........] - ETA: 1s\r\n",
      "250642432/359746192 [===================>..........] - ETA: 1s\r\n",
      "256696320/359746192 [====================>.........] - ETA: 0s\r\n",
      "262266880/359746192 [====================>.........] - ETA: 0s\r\n",
      "267632640/359746192 [=====================>........] - ETA: 0s\r\n",
      "272670720/359746192 [=====================>........] - ETA: 0s\r\n",
      "277602304/359746192 [======================>.......] - ETA: 0s\r\n",
      "282656768/359746192 [======================>.......] - ETA: 0s\r\n",
      "284147712/359746192 [======================>.......] - ETA: 0s\r\n",
      "289406976/359746192 [=======================>......] - ETA: 0s\r\n",
      "294895616/359746192 [=======================>......] - ETA: 0s\r\n",
      "300384256/359746192 [========================>.....] - ETA: 0s\r\n",
      "306446336/359746192 [========================>.....] - ETA: 0s\r\n",
      "312418304/359746192 [=========================>....] - ETA: 0s\r\n",
      "317538304/359746192 [=========================>....] - ETA: 0s\r\n",
      "322887680/359746192 [=========================>....] - ETA: 0s\r\n",
      "327909376/359746192 [==========================>...] - ETA: 0s\r\n",
      "332619776/359746192 [==========================>...] - ETA: 0s\r\n",
      "337920000/359746192 [===========================>..] - ETA: 0s\r\n",
      "342958080/359746192 [===========================>..] - ETA: 0s\r\n",
      "348012544/359746192 [============================>.] - ETA: 0s\r\n",
      "353017856/359746192 [============================>.] - ETA: 0s\r\n",
      "358023168/359746192 [============================>.] - ETA: 0s\r\n",
      "359751680/359746192 [==============================] - 3s 0us/step\r\n",
      "{\"timestamp\": \"2018-06-15T13:39:43.549679Z\", \"host\": \"azure-dl-7fdd7b85d5-lk2m7\", \"path\": \"/code/driver.py\", \"tags\": [], \"level\": \"INFO\", \"logger\": \"model_driver\", \"message\": \"Model loading time: 57600.32 ms\", \"stack_info\": null}\r\n",
      "Initialising\r\n",
      "{\"timestamp\": \"2018-06-15T13:39:43.558446Z\", \"host\": \"azure-dl-7fdd7b85d5-lk2m7\", \"path\": \"/opt/conda/envs/py3.5/lib/python3.5/site-packages/werkzeug/_internal.py\", \"tags\": [], \"level\": \"INFO\", \"logger\": \"werkzeug\", \"msg\": \" * Running on %s://%s:%d/ %s\", \"message\": \" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\", \"stack_info\": null}\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs azure-dl-7fdd7b85d5-lk2m7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tear it all down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done with your cluster you can use the following two commands to destroy it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"azure-dl\" deleted\n",
      "service \"azure-dl\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f az-dl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az aks delete -n $aks_name -g $resource_group -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[0minished .."
     ]
    }
   ],
   "source": [
    "!az group delete --name $resource_group -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aksenv]",
   "language": "python",
   "name": "conda-env-aksenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
