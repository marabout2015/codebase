{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Web App on Azure Container Services (AKS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will set up an Azure Container Service which will be managed by Kubernetes. We will then take the Docker image we created earlier that contains our app and deploy it to the AKS cluster. Then, we will check everything is working by sending an image to it and getting it scored. \n",
    "\n",
    "The process is split into the following steps:\n",
    "- Define our resource names\n",
    "- Login to Azure\n",
    "- Create resource group and create AKS\n",
    "- Connect to AKS\n",
    "- Deploy our app\n",
    "- Tear it all down\n",
    "\n",
    "We assume that this notebook is running on Linux and Azure CLI is installed before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the various name definitions for the resources needed to setup AKS as well as the name of the Docker image we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Please modify the below as you see fit\n",
    "resource_group = \"<RESOURCE_GROUP>\" \n",
    "aks_name = \"<AKS_CLUSTER_NAME>\"\n",
    "location = \"eastus\"\n",
    "\n",
    "image_name = '<YOUR_DOCKER_IMAGE>' # 'fboylu/kerastf-gpu' Feel free to use this image if you want to \n",
    "                                   # skip creating your own container\n",
    "selected_subscription = \"'<YOUR_SUBSCRIPTION>'\" # If you have multiple subscriptions select \n",
    "                                                # the subscription you want to use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_group = \"fbaksrg\" # Feel free to modify these\n",
    "aks_name = \"fbAKSClustergpu\"\n",
    "location = \"eastus\"\n",
    "\n",
    "image_name = \"fboylu/kerasres50-gpu\" \n",
    "selected_subscription = \"'Team Danielle Internal'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure account login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below will initiate a login to your Azure account. It will pop up with an url to go to where you will enter a one off code and log into your Azure account using your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az account set --subscription $selected_subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"environmentName\": \"AzureCloud\",\r\n",
      "  \"id\": \"edf507a2-6235-46c5-b560-fd463ba2e771\",\r\n",
      "  \"isDefault\": true,\r\n",
      "  \"name\": \"Team Danielle Internal\",\r\n",
      "  \"state\": \"Enabled\",\r\n",
      "  \"tenantId\": \"72f988bf-86f1-41af-91ab-2d7cd011db47\",\r\n",
      "  \"user\": {\r\n",
      "    \"name\": \"fboylu@microsoft.com\",\r\n",
      "    \"type\": \"user\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az account show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to register the container service resources on your subscription if you haven't already done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az provider register -n Microsoft.ContainerService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!az provider show -n Microsoft.ContainerService"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create resources and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create resource group and AKS cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure encourages the use of groups to organize all the Azure components you deploy. That way it is easier to find them but also we can delete a number of resources simply by deleting the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/fbaksrg\",\r\n",
      "  \"location\": \"eastus\",\r\n",
      "  \"managedBy\": null,\r\n",
      "  \"name\": \"fbaksrg\",\r\n",
      "  \"properties\": {\r\n",
      "    \"provisioningState\": \"Succeeded\"\r\n",
      "  },\r\n",
      "  \"tags\": null\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!az group create --name $resource_group --location $location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create the AKS cluster in the resource group we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"count\": 1,\n",
      "      \"dnsPrefix\": null,\n",
      "      \"fqdn\": null,\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"osDiskSizeGb\": null,\n",
      "      \"osType\": \"Linux\",\n",
      "      \"ports\": null,\n",
      "      \"storageProfile\": \"ManagedDisks\",\n",
      "      \"vmSize\": \"Standard_NC6\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"dnsPrefix\": \"fbAKSClust-fbaksrg-edf507\",\n",
      "  \"fqdn\": \"fbaksclust-fbaksrg-edf507-e12d7f40.hcp.eastus.azmk8s.io\",\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/fbaksrg/providers/Microsoft.ContainerService/managedClusters/fbAKSClustergpu\",\n",
      "  \"kubernetesVersion\": \"1.9.6\",\n",
      "  \"linuxProfile\": {\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDTZYQFHNstYCR25qtvMrC6baTMS6TobaIRbgd0xOoafDy+2uBk0DMJuhGWoOcrsCnvadp5k/0K8qBRysyhlQGWb6+r8fBunThy+zpTKqdh3W8Q1y5UtKnGwwU1cqGXDOPUIXJYNPJqUKV829+MOrZjUynhHgSzDbY2ncGyoT+Farsvm01aGEdDapa+XRl4JAwtN1bb9q+Ii5y+MkpIOhLRMwATl05eNfAHmYQWtaIJZZJOHMNPswlBmLs293Wsj11vYh6/yo9S4ToEsc9Pbl5Zn6OFIu7jfzN2bM8cA3+8pru9WSthrxjJvPn8i4uTYozOdNIi09ArQ4lRT9t6rsMz\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"fbAKSClustergpu\",\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"fbaksrg\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"clientId\": \"eeba3bfe-45f9-42de-9bdb-54416b67382d\",\n",
      "    \"keyVaultSecretRef\": null,\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\"\n",
      "}\n",
      "\u001b[0mCPU times: user 15.4 s, sys: 5.92 s, total: 21.3 s\n",
      "Wall time: 15min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!az aks create --resource-group $resource_group --name $aks_name --node-count 1 --generate-ssh-keys -s Standard_NC6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install kubectl CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the Kubernetes cluster, we will use kubectl, the Kubernetes command-line client. To install, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDownloading client to /usr/local/bin/kubectl from https://storage.googleapis.com/kubernetes-release/release/v1.10.4/bin/linux/amd64/kubectl\u001b[0m\n",
      "\u001b[33mPlease ensure that /usr/local/bin is in your search PATH, so the `kubectl` command can be found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo az aks install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AKS cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure kubectl to connect to the Kubernetes cluster, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged \"fbAKSClustergpu\" as current context in /home/fboylu/.kube/config\r\n"
     ]
    }
   ],
   "source": [
    "!az aks get-credentials --resource-group $resource_group --name $aks_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify connection by listing the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       STATUS    ROLES     AGE       VERSION\r\n",
      "aks-nodepool1-28016997-0   Ready     agent     25m       v1.9.6\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the pods on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "kube-system   azureproxy-79c5db744-r5ggd              1/1       Running   2          29m\r\n",
      "kube-system   heapster-55f855b47-4m7xr                2/2       Running   0          24m\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-4z4z6           3/3       Running   0          29m\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-mp5fh           3/3       Running   0          29m\r\n",
      "kube-system   kube-proxy-k8t2c                        1/1       Running   0          26m\r\n",
      "kube-system   kube-svc-redirect-z6ppp                 1/1       Running   0          26m\r\n",
      "kube-system   kubernetes-dashboard-546f987686-8krxm   1/1       Running   2          29m\r\n",
      "kube-system   tunnelfront-695bcbdc68-t4l8t            1/1       Running   0          29m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define our Kubernetes manifest file for our service and load balancer. Note that we have to specify the volume mounts to the drivers that are located on the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_template = {\n",
    "  \"apiVersion\": \"apps/v1beta1\",\n",
    "  \"kind\": \"Deployment\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"replicas\":1,\n",
    "      \"template\":{\n",
    "          \"metadata\":{\n",
    "              \"labels\":{\n",
    "                  \"app\":\"azure-dl\"\n",
    "              }\n",
    "          },\n",
    "          \"spec\":{\n",
    "              \"containers\":[\n",
    "                  {\n",
    "                      \"name\": \"azure-dl\",\n",
    "                      \"image\": \"fboylu/kerasres50-gpu\",\n",
    "                      \"env\":[\n",
    "                          {\n",
    "                              \"name\": \"LD_LIBRARY_PATH\",\n",
    "                              \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.5/lib\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"ports\":[\n",
    "                          {\n",
    "                              \"containerPort\":80,\n",
    "                              \"name\":\"model\"\n",
    "                          }\n",
    "                      ],\n",
    "                      \"volumeMounts\":[\n",
    "                          {\n",
    "                              \"mountPath\":\"/usr/local/nvidia\",\n",
    "                              \"name\": \"nvidia\",\n",
    "                          }\n",
    "                      ],\n",
    "                      \"resources\":{\n",
    "                           \"requests\":{\n",
    "                               \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                           },\n",
    "                           \"limits\":{\n",
    "                               \"alpha.kubernetes.io/nvidia-gpu\": 1\n",
    "                           }\n",
    "                       }  \n",
    "                  }\n",
    "              ],\n",
    "              \"volumes\":[\n",
    "                  {\n",
    "                      \"name\": \"nvidia\",\n",
    "                      \"hostPath\":{\n",
    "                          \"path\":\"/usr/local/nvidia\"\n",
    "                      },\n",
    "                  },\n",
    "              ]\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "service_temp = {\n",
    "  \"apiVersion\": \"v1\",\n",
    "  \"kind\": \"Service\",\n",
    "  \"metadata\": {\n",
    "      \"name\": \"azure-dl\"\n",
    "  },\n",
    "  \"spec\":{\n",
    "      \"type\": \"LoadBalancer\",\n",
    "      \"ports\":[\n",
    "          {\n",
    "              \"port\":80\n",
    "          }\n",
    "      ],\n",
    "      \"selector\":{\n",
    "            \"app\":\"azure-dl\"\n",
    "      }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write_json_to_file(json_dict, filename, mode='w'):\n",
    "    with open(filename, mode) as outfile:\n",
    "        json.dump(json_dict, outfile, indent=4, sort_keys=True)\n",
    "        outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_to_file(app_template, 'az-dl.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_to_file(service_temp, 'az-dl.json', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the manifest created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"apiVersion\": \"apps/v1beta1\",\r\n",
      "    \"kind\": \"Deployment\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"replicas\": 1,\r\n",
      "        \"template\": {\r\n",
      "            \"metadata\": {\r\n",
      "                \"labels\": {\r\n",
      "                    \"app\": \"azure-dl\"\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"spec\": {\r\n",
      "                \"containers\": [\r\n",
      "                    {\r\n",
      "                        \"env\": [\r\n",
      "                            {\r\n",
      "                                \"name\": \"LD_LIBRARY_PATH\",\r\n",
      "                                \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.5/lib\"\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"image\": \"fboylu/kerasres50-gpu\",\r\n",
      "                        \"name\": \"azure-dl\",\r\n",
      "                        \"ports\": [\r\n",
      "                            {\r\n",
      "                                \"containerPort\": 80,\r\n",
      "                                \"name\": \"model\"\r\n",
      "                            }\r\n",
      "                        ],\r\n",
      "                        \"resources\": {\r\n",
      "                            \"limits\": {\r\n",
      "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\r\n",
      "                            },\r\n",
      "                            \"requests\": {\r\n",
      "                                \"alpha.kubernetes.io/nvidia-gpu\": 1\r\n",
      "                            }\r\n",
      "                        },\r\n",
      "                        \"volumeMounts\": [\r\n",
      "                            {\r\n",
      "                                \"mountPath\": \"/usr/local/nvidia\",\r\n",
      "                                \"name\": \"nvidia\"\r\n",
      "                            }\r\n",
      "                        ]\r\n",
      "                    }\r\n",
      "                ],\r\n",
      "                \"volumes\": [\r\n",
      "                    {\r\n",
      "                        \"hostPath\": {\r\n",
      "                            \"path\": \"/usr/local/nvidia\"\r\n",
      "                        },\r\n",
      "                        \"name\": \"nvidia\"\r\n",
      "                    }\r\n",
      "                ]\r\n",
      "            }\r\n",
      "        }\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n",
      "{\r\n",
      "    \"apiVersion\": \"v1\",\r\n",
      "    \"kind\": \"Service\",\r\n",
      "    \"metadata\": {\r\n",
      "        \"name\": \"azure-dl\"\r\n",
      "    },\r\n",
      "    \"spec\": {\r\n",
      "        \"ports\": [\r\n",
      "            {\r\n",
      "                \"port\": 80\r\n",
      "            }\r\n",
      "        ],\r\n",
      "        \"selector\": {\r\n",
      "            \"app\": \"azure-dl\"\r\n",
      "        },\r\n",
      "        \"type\": \"LoadBalancer\"\r\n",
      "    }\r\n",
      "}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat az-dl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use kubectl create command to deploy our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"azure-dl\" created\n",
      "service \"azure-dl\" created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f az-dl.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the pod is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS             RESTARTS   AGE\r\n",
      "default       azure-dl-7677f788fc-ld67s               1/1       Running            0          2h\r\n",
      "default       azure-dl-7677f788fc-lv97p               1/1       Running            0          41m\r\n",
      "default       azure-dl-7677f788fc-wnmff               0/1       ImagePullBackOff   0          7m\r\n",
      "kube-system   azureproxy-79c5db744-r5ggd              1/1       Running            2          2h\r\n",
      "kube-system   heapster-55f855b47-4m7xr                2/2       Running            0          2h\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-4z4z6           3/3       Running            0          2h\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-mp5fh           3/3       Running            0          2h\r\n",
      "kube-system   kube-proxy-ghjwk                        1/1       Running            0          47m\r\n",
      "kube-system   kube-proxy-jmv6n                        1/1       Running            0          10m\r\n",
      "kube-system   kube-proxy-k8t2c                        1/1       Running            0          2h\r\n",
      "kube-system   kube-svc-redirect-gr6ks                 1/1       Running            0          10m\r\n",
      "kube-system   kube-svc-redirect-ldxlv                 1/1       Running            0          47m\r\n",
      "kube-system   kube-svc-redirect-z6ppp                 1/1       Running            0          2h\r\n",
      "kube-system   kubernetes-dashboard-546f987686-8krxm   1/1       Running            2          2h\r\n",
      "kube-system   tunnelfront-695bcbdc68-t4l8t            1/1       Running            0          2h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything goes wrong you can use the commands below to observe the events on the node as well as review the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST SEEN   FIRST SEEN   COUNT     NAME                                         KIND         SUBOBJECT                   TYPE      REASON                    SOURCE                                 MESSAGE\r\n",
      "53m         53m          1         aks-nodepool1-28016997-0.1536381ffc8ee781    Node                                     Normal    RegisteredNode            node-controller                        Node aks-nodepool1-28016997-0 event: Registered Node aks-nodepool1-28016997-0 in Controller\r\n",
      "14m         14m          1         aks-nodepool1-28016997-0.15363a3d422b73c7    Node                                     Normal    RegisteredNode            node-controller                        Node aks-nodepool1-28016997-0 event: Registered Node aks-nodepool1-28016997-0 in Controller\r\n",
      "47m         47m          1         aks-nodepool1-28016997-1.15363872946e7e16    Node                                     Normal    Starting                  kubelet, aks-nodepool1-28016997-1      Starting kubelet.\r\n",
      "47m         47m          2         aks-nodepool1-28016997-1.153638729789b379    Node                                     Normal    NodeHasSufficientDisk     kubelet, aks-nodepool1-28016997-1      Node aks-nodepool1-28016997-1 status is now: NodeHasSufficientDisk\r\n",
      "47m         47m          2         aks-nodepool1-28016997-1.15363872978a09cd    Node                                     Normal    NodeHasSufficientMemory   kubelet, aks-nodepool1-28016997-1      Node aks-nodepool1-28016997-1 status is now: NodeHasSufficientMemory\r\n",
      "47m         47m          2         aks-nodepool1-28016997-1.15363872978a32d1    Node                                     Normal    NodeHasNoDiskPressure     kubelet, aks-nodepool1-28016997-1      Node aks-nodepool1-28016997-1 status is now: NodeHasNoDiskPressure\r\n",
      "47m         47m          1         aks-nodepool1-28016997-1.15363872985b1f62    Node                                     Normal    NodeAllocatableEnforced   kubelet, aks-nodepool1-28016997-1      Updated Node Allocatable limit across pods\r\n",
      "47m         47m          1         aks-nodepool1-28016997-1.15363872a5d0c741    Node                                     Normal    RegisteredNode            node-controller                        Node aks-nodepool1-28016997-1 event: Registered Node aks-nodepool1-28016997-1 in Controller\r\n",
      "47m         47m          1         aks-nodepool1-28016997-1.153638765dd5b3e0    Node                                     Normal    Starting                  kube-proxy, aks-nodepool1-28016997-1   Starting kube-proxy.\r\n",
      "47m         47m          1         aks-nodepool1-28016997-1.153638774ca50c6a    Node                                     Normal    NodeReady                 kubelet, aks-nodepool1-28016997-1      Node aks-nodepool1-28016997-1 status is now: NodeReady\r\n",
      "14m         14m          1         aks-nodepool1-28016997-1.15363a3d422c6e91    Node                                     Normal    RegisteredNode            node-controller                        Node aks-nodepool1-28016997-1 event: Registered Node aks-nodepool1-28016997-1 in Controller\r\n",
      "10m         10m          1         aks-nodepool1-28016997-2.15363a779f6b502d    Node                                     Normal    Starting                  kubelet, aks-nodepool1-28016997-2      Starting kubelet.\r\n",
      "10m         10m          2         aks-nodepool1-28016997-2.15363a77a1b6416b    Node                                     Normal    NodeHasSufficientDisk     kubelet, aks-nodepool1-28016997-2      Node aks-nodepool1-28016997-2 status is now: NodeHasSufficientDisk\r\n",
      "10m         10m          2         aks-nodepool1-28016997-2.15363a77a1b67433    Node                                     Normal    NodeHasSufficientMemory   kubelet, aks-nodepool1-28016997-2      Node aks-nodepool1-28016997-2 status is now: NodeHasSufficientMemory\r\n",
      "10m         10m          2         aks-nodepool1-28016997-2.15363a77a1b69823    Node                                     Normal    NodeHasNoDiskPressure     kubelet, aks-nodepool1-28016997-2      Node aks-nodepool1-28016997-2 status is now: NodeHasNoDiskPressure\r\n",
      "10m         10m          1         aks-nodepool1-28016997-2.15363a77a28ce3e9    Node                                     Normal    NodeAllocatableEnforced   kubelet, aks-nodepool1-28016997-2      Updated Node Allocatable limit across pods\r\n",
      "10m         10m          1         aks-nodepool1-28016997-2.15363a78a28bf339    Node                                     Normal    RegisteredNode            node-controller                        Node aks-nodepool1-28016997-2 event: Registered Node aks-nodepool1-28016997-2 in Controller\r\n",
      "10m         10m          1         aks-nodepool1-28016997-2.15363a7abfb6d75f    Node                                     Normal    Starting                  kube-proxy, aks-nodepool1-28016997-2   Starting kube-proxy.\r\n",
      "10m         10m          1         aks-nodepool1-28016997-2.15363a7c55de96f9    Node                                     Normal    NodeReady                 kubelet, aks-nodepool1-28016997-2      Node aks-nodepool1-28016997-2 status is now: NodeReady\r\n",
      "41m         41m          1         azure-dl-7677f788fc-lv97p.153638cbb63ec7e6   Pod                                      Normal    Scheduled                 default-scheduler                      Successfully assigned azure-dl-7677f788fc-lv97p to aks-nodepool1-28016997-1\r\n",
      "41m         41m          1         azure-dl-7677f788fc-lv97p.153638cbc8c30fe9   Pod                                      Normal    SuccessfulMountVolume     kubelet, aks-nodepool1-28016997-1      MountVolume.SetUp succeeded for volume \"nvidia\" \r\n",
      "41m         41m          1         azure-dl-7677f788fc-lv97p.153638cbca53ad3e   Pod                                      Normal    SuccessfulMountVolume     kubelet, aks-nodepool1-28016997-1      MountVolume.SetUp succeeded for volume \"default-token-crgnj\" \r\n",
      "39m         41m          2         azure-dl-7677f788fc-lv97p.153638cc0b56f3ad   Pod          spec.containers{azure-dl}   Normal    Pulling                   kubelet, aks-nodepool1-28016997-1      pulling image \"fboylu/kerasres50-gpu\"\r\n",
      "39m         39m          1         azure-dl-7677f788fc-lv97p.153638e206935ec6   Pod          spec.containers{azure-dl}   Warning   Failed                    kubelet, aks-nodepool1-28016997-1      Failed to pull image \"fboylu/kerasres50-gpu\": rpc error: code = Canceled desc = context canceled\r\n",
      "39m         39m          1         azure-dl-7677f788fc-lv97p.153638e20693b3ee   Pod          spec.containers{azure-dl}   Warning   Failed                    kubelet, aks-nodepool1-28016997-1      Error: ErrImagePull\r\n",
      "39m         39m          1         azure-dl-7677f788fc-lv97p.153638e230f4dfb6   Pod                                      Normal    SandboxChanged            kubelet, aks-nodepool1-28016997-1      Pod sandbox changed, it will be killed and re-created.\r\n",
      "39m         39m          3         azure-dl-7677f788fc-lv97p.153638e37a50d5a5   Pod          spec.containers{azure-dl}   Normal    BackOff                   kubelet, aks-nodepool1-28016997-1      Back-off pulling image \"fboylu/kerasres50-gpu\"\r\n",
      "39m         39m          3         azure-dl-7677f788fc-lv97p.153638e37a510679   Pod          spec.containers{azure-dl}   Warning   Failed                    kubelet, aks-nodepool1-28016997-1      Error: ImagePullBackOff\r\n",
      "35m         35m          1         azure-dl-7677f788fc-lv97p.1536391fb8bf2e7b   Pod          spec.containers{azure-dl}   Normal    Pulled                    kubelet, aks-nodepool1-28016997-1      Successfully pulled image \"fboylu/kerasres50-gpu\"\r\n",
      "35m         35m          1         azure-dl-7677f788fc-lv97p.1536391fc793d584   Pod          spec.containers{azure-dl}   Normal    Created                   kubelet, aks-nodepool1-28016997-1      Created container\r\n",
      "35m         35m          1         azure-dl-7677f788fc-lv97p.1536391fd004b7bd   Pod          spec.containers{azure-dl}   Normal    Started                   kubelet, aks-nodepool1-28016997-1      Started container\r\n",
      "6m          6m           1         azure-dl-7677f788fc-wnmff.15363aae2c505b3c   Pod                                      Normal    Scheduled                 default-scheduler                      Successfully assigned azure-dl-7677f788fc-wnmff to aks-nodepool1-28016997-2\r\n",
      "6m          6m           1         azure-dl-7677f788fc-wnmff.15363aae3c6bbed1   Pod                                      Normal    SuccessfulMountVolume     kubelet, aks-nodepool1-28016997-2      MountVolume.SetUp succeeded for volume \"nvidia\" \r\n",
      "6m          6m           1         azure-dl-7677f788fc-wnmff.15363aae3d3c5e65   Pod                                      Normal    SuccessfulMountVolume     kubelet, aks-nodepool1-28016997-2      MountVolume.SetUp succeeded for volume \"default-token-crgnj\" \r\n",
      "2m          6m           3         azure-dl-7677f788fc-wnmff.15363aae787cdde4   Pod          spec.containers{azure-dl}   Normal    Pulling                   kubelet, aks-nodepool1-28016997-2      pulling image \"fboylu/kerasres50-gpu\"\r\n",
      "3m          5m           2         azure-dl-7677f788fc-wnmff.15363ac4b3c119c0   Pod          spec.containers{azure-dl}   Warning   Failed                    kubelet, aks-nodepool1-28016997-2      Failed to pull image \"fboylu/kerasres50-gpu\": rpc error: code = Canceled desc = context canceled\r\n",
      "3m          5m           2         azure-dl-7677f788fc-wnmff.15363ac4b3c170db   Pod          spec.containers{azure-dl}   Warning   Failed                    kubelet, aks-nodepool1-28016997-2      Error: ErrImagePull\r\n",
      "3m          5m           2         azure-dl-7677f788fc-wnmff.15363ac4f9210dcd   Pod          spec.containers{azure-dl}   Normal    BackOff                   kubelet, aks-nodepool1-28016997-2      Back-off pulling image \"fboylu/kerasres50-gpu\"\r\n",
      "3m          5m           2         azure-dl-7677f788fc-wnmff.15363ac4f9213f05   Pod          spec.containers{azure-dl}   Warning   Failed                    kubelet, aks-nodepool1-28016997-2      Error: ImagePullBackOff\r\n",
      "41m         41m          1         azure-dl-7677f788fc.153638cbb4df9c79         ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller                  Created pod: azure-dl-7677f788fc-lv97p\r\n",
      "6m          6m           1         azure-dl-7677f788fc.15363aae2c111f56         ReplicaSet                               Normal    SuccessfulCreate          replicaset-controller                  Created pod: azure-dl-7677f788fc-wnmff\r\n",
      "53m         53m          1         azure-dl.1536381fe5026d87                    Service                                  Normal    EnsuringLoadBalancer      service-controller                     Ensuring load balancer\r\n",
      "53m         53m          1         azure-dl.153638203a5227e9                    Service                                  Normal    EnsuredLoadBalancer       service-controller                     Ensured load balancer\r\n",
      "46m         46m          1         azure-dl.15363889e4813311                    Service                                  Normal    UpdatedLoadBalancer       service-controller                     Updated load balancer with new hosts\r\n",
      "41m         41m          1         azure-dl.153638cbb36fa51c                    Deployment                               Normal    ScalingReplicaSet         deployment-controller                  Scaled up replica set azure-dl-7677f788fc to 2\r\n",
      "14m         14m          1         azure-dl.15363a3d3088feaf                    Service                                  Normal    EnsuringLoadBalancer      service-controller                     Ensuring load balancer\r\n",
      "14m         14m          1         azure-dl.15363a3d8f9c9be8                    Service                                  Normal    EnsuredLoadBalancer       service-controller                     Ensured load balancer\r\n",
      "9m          9m           1         azure-dl.15363a87efd8a019                    Service                                  Normal    UpdatedLoadBalancer       service-controller                     Updated load balancer with new hosts\r\n",
      "6m          6m           1         azure-dl.15363aae2aa6aae7                    Deployment                               Normal    ScalingReplicaSet         deployment-controller                  Scaled up replica set azure-dl-7677f788fc to 3\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the logs for the application pod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_json = !kubectl get pods -o json\n",
    "pod_dict = json.loads(''.join(pod_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-08 13:59:47,185 CRIT Supervisor running as root (no user in config file)\r\n",
      "2018-06-08 13:59:47,188 INFO supervisord started with pid 1\r\n",
      "2018-06-08 13:59:48,190 INFO spawned: 'program_exit' with pid 10\r\n",
      "2018-06-08 13:59:48,192 INFO spawned: 'nginx' with pid 11\r\n",
      "2018-06-08 13:59:48,193 INFO spawned: 'gunicorn' with pid 12\r\n",
      "2018-06-08 13:59:49,226 INFO success: program_exit entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)\r\n",
      "2018-06-08 13:59:49.604948: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n",
      "2018-06-08 13:59:49.796415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \r\n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\n",
      "pciBusID: ddde:00:00.0\r\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\r\n",
      "2018-06-08 13:59:49.796461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\r\n",
      "2018-06-08 13:59:50.117612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10765 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: ddde:00:00.0, compute capability: 3.7)\r\n",
      "2018-06-08 13:59:54,122 INFO success: nginx entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)\r\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\r\n",
      "\r\n",
      "     8192/102853048 [..............................] - ETA: 28s\r\n",
      "   663552/102853048 [..............................] - ETA: 8s \r\n",
      "  1851392/102853048 [..............................] - ETA: 5s\r\n",
      "  3620864/102853048 [>.............................] - ETA: 4s\r\n",
      "  5275648/102853048 [>.............................] - ETA: 3s\r\n",
      "  5521408/102853048 [>.............................] - ETA: 4s\r\n",
      "  6848512/102853048 [>.............................] - ETA: 4s\r\n",
      "  7561216/102853048 [=>............................] - ETA: 4s\r\n",
      "  7757824/102853048 [=>............................] - ETA: 6s\r\n",
      "  9502720/102853048 [=>............................] - ETA: 5s\r\n",
      " 11075584/102853048 [==>...........................] - ETA: 6s\r\n",
      " 12836864/102853048 [==>...........................] - ETA: 5s\r\n",
      " 14909440/102853048 [===>..........................] - ETA: 4s\r\n",
      " 16826368/102853048 [===>..........................] - ETA: 4s\r\n",
      " 18702336/102853048 [====>.........................] - ETA: 4s\r\n",
      " 20512768/102853048 [====>.........................] - ETA: 4s\r\n",
      " 22724608/102853048 [=====>........................] - ETA: 3s\r\n",
      " 24584192/102853048 [======>.......................] - ETA: 3s\r\n",
      " 26796032/102853048 [======>.......................] - ETA: 3s\r\n",
      " 29007872/102853048 [=======>......................] - ETA: 3s\r\n",
      " 30867456/102853048 [========>.....................] - ETA: 2s\r\n",
      " 32579584/102853048 [========>.....................] - ETA: 2s\r\n",
      " 34299904/102853048 [=========>....................] - ETA: 2s\r\n",
      " 35725312/102853048 [=========>....................] - ETA: 2s\r\n",
      " 37240832/102853048 [=========>....................] - ETA: 2s\r\n",
      " 38739968/102853048 [==========>...................] - ETA: 2s\r\n",
      " 40181760/102853048 [==========>...................] - ETA: 2s\r\n",
      " 41263104/102853048 [===========>..................] - ETA: 2s\r\n",
      " 42704896/102853048 [===========>..................] - ETA: 2s\r\n",
      " 44154880/102853048 [===========>..................] - ETA: 2s\r\n",
      " 45490176/102853048 [============>.................] - ETA: 2s\r\n",
      " 47063040/102853048 [============>.................] - ETA: 2s\r\n",
      " 48889856/102853048 [=============>................] - ETA: 2s\r\n",
      " 50888704/102853048 [=============>................] - ETA: 1s\r\n",
      " 52617216/102853048 [==============>...............] - ETA: 1s\r\n",
      " 53190656/102853048 [==============>...............] - ETA: 1s\r\n",
      " 54247424/102853048 [==============>...............] - ETA: 1s\r\n",
      " 55517184/102853048 [===============>..............] - ETA: 1s\r\n",
      " 56680448/102853048 [===============>..............] - ETA: 1s\r\n",
      " 57278464/102853048 [===============>..............] - ETA: 1s\r\n",
      " 59056128/102853048 [================>.............] - ETA: 1s\r\n",
      " 61489152/102853048 [================>.............] - ETA: 1s\r\n",
      " 63995904/102853048 [=================>............] - ETA: 1s\r\n",
      " 66625536/102853048 [==================>...........] - ETA: 1s\r\n",
      " 68263936/102853048 [==================>...........] - ETA: 1s\r\n",
      " 69615616/102853048 [===================>..........] - ETA: 1s\r\n",
      " 70344704/102853048 [===================>..........] - ETA: 1s\r\n",
      " 71262208/102853048 [===================>..........] - ETA: 1s\r\n",
      " 73940992/102853048 [====================>.........] - ETA: 1s\r\n",
      " 76292096/102853048 [=====================>........] - ETA: 0s\r\n",
      " 78635008/102853048 [=====================>........] - ETA: 0s\r\n",
      " 78970880/102853048 [======================>.......] - ETA: 0s\r\n",
      " 81084416/102853048 [======================>.......] - ETA: 0s\r\n",
      " 81559552/102853048 [======================>.......] - ETA: 0s\r\n",
      " 83574784/102853048 [=======================>......] - ETA: 0s\r\n",
      " 85590016/102853048 [=======================>......] - ETA: 0s\r\n",
      " 87662592/102853048 [========================>.....] - ETA: 0s\r\n",
      " 89800704/102853048 [=========================>....] - ETA: 0s\r\n",
      " 92102656/102853048 [=========================>....] - ETA: 0s\r\n",
      " 94257152/102853048 [==========================>...] - ETA: 0s\r\n",
      " 94879744/102853048 [==========================>...] - ETA: 0s\r\n",
      " 96518144/102853048 [===========================>..] - ETA: 0s\r\n",
      " 97714176/102853048 [===========================>..] - ETA: 0s\r\n",
      " 98721792/102853048 [===========================>..] - ETA: 0s\r\n",
      " 99975168/102853048 [============================>.] - ETA: 0s\r\n",
      "101195776/102853048 [============================>.] - ETA: 0s\r\n",
      "102621184/102853048 [============================>.] - ETA: 0s\r\n",
      "102858752/102853048 [==============================] - 4s 0us/step\r\n",
      "{\"tags\": [], \"stack_info\": null, \"message\": \"Model loading time: 12164.39 ms\", \"level\": \"INFO\", \"path\": \"/code/driver.py\", \"host\": \"azure-dl-7677f788fc-ld67s\", \"timestamp\": \"2018-06-08T14:00:01.737978Z\", \"logger\": \"model_driver\"}\r\n",
      "Initialising\r\n",
      "{\"tags\": [], \"stack_info\": null, \"message\": \" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\", \"level\": \"INFO\", \"msg\": \" * Running on %s://%s:%d/ %s\", \"path\": \"/opt/conda/envs/py3.5/lib/python3.5/site-packages/werkzeug/_internal.py\", \"host\": \"azure-dl-7677f788fc-ld67s\", \"timestamp\": \"2018-06-08T14:00:01.744609Z\", \"logger\": \"werkzeug\"}\r\n",
      "2018-06-08 14:00:08,752 INFO success: gunicorn entered RUNNING state, process has stayed up for > than 20 seconds (startsecs)\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs {pod_dict['items'][0]['metadata']['name']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\r\n",
      "azure-dl   2         2         2            2           1h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can take a few minutes for the service to populate the EXTERNAL-IP field below. This will be the IP you use to call the service. You can also specify an IP to use, please see the AKS documentation for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)        AGE\r\n",
      "azure-dl   LoadBalancer   10.0.150.121   40.121.69.40   80:31965/TCP   18m\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get service azure-dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will [test our web application deployed on AKS](05_TestWebApp.ipynb). Once, we are done with all the notebooks of the tutorial, below instructions can be used to delete the cluster and free resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"count\": 3,\n",
      "      \"dnsPrefix\": null,\n",
      "      \"fqdn\": null,\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"osDiskSizeGb\": null,\n",
      "      \"osType\": \"Linux\",\n",
      "      \"ports\": null,\n",
      "      \"storageProfile\": \"ManagedDisks\",\n",
      "      \"vmSize\": \"Standard_NC6\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"dnsPrefix\": \"fbAKSClust-fbaksrg-edf507\",\n",
      "  \"fqdn\": \"fbaksclust-fbaksrg-edf507-e12d7f40.hcp.eastus.azmk8s.io\",\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/fbaksrg/providers/Microsoft.ContainerService/managedClusters/fbAKSClustergpu\",\n",
      "  \"kubernetesVersion\": \"1.9.6\",\n",
      "  \"linuxProfile\": {\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDTZYQFHNstYCR25qtvMrC6baTMS6TobaIRbgd0xOoafDy+2uBk0DMJuhGWoOcrsCnvadp5k/0K8qBRysyhlQGWb6+r8fBunThy+zpTKqdh3W8Q1y5UtKnGwwU1cqGXDOPUIXJYNPJqUKV829+MOrZjUynhHgSzDbY2ncGyoT+Farsvm01aGEdDapa+XRl4JAwtN1bb9q+Ii5y+MkpIOhLRMwATl05eNfAHmYQWtaIJZZJOHMNPswlBmLs293Wsj11vYh6/yo9S4ToEsc9Pbl5Zn6OFIu7jfzN2bM8cA3+8pru9WSthrxjJvPn8i4uTYozOdNIi09ArQ4lRT9t6rsMz\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"fbAKSClustergpu\",\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"fbaksrg\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"clientId\": \"eeba3bfe-45f9-42de-9bdb-54416b67382d\",\n",
      "    \"keyVaultSecretRef\": null,\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az aks scale --resource-group=$resource_group --name=$aks_name --node-count 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       STATUS    ROLES     AGE       VERSION\r\n",
      "aks-nodepool1-28016997-0   Ready     agent     2h        v1.9.6\r\n",
      "aks-nodepool1-28016997-1   Ready     agent     40m       v1.9.6\r\n",
      "aks-nodepool1-28016997-2   Ready     agent     3m        v1.9.6\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions \"azure-dl\" scaled\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl scale --current-replicas=2 --replicas=3 deployment/azure-dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE     NAME                                    READY     STATUS    RESTARTS   AGE\r\n",
      "default       azure-dl-7677f788fc-ld67s               1/1       Running   0          2h\r\n",
      "default       azure-dl-7677f788fc-lv97p               1/1       Running   0          44m\r\n",
      "default       azure-dl-7677f788fc-wnmff               1/1       Running   0          10m\r\n",
      "kube-system   azureproxy-79c5db744-r5ggd              1/1       Running   2          2h\r\n",
      "kube-system   heapster-55f855b47-4m7xr                2/2       Running   0          2h\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-4z4z6           3/3       Running   0          2h\r\n",
      "kube-system   kube-dns-v20-7c556f89c5-mp5fh           3/3       Running   0          2h\r\n",
      "kube-system   kube-proxy-ghjwk                        1/1       Running   0          51m\r\n",
      "kube-system   kube-proxy-jmv6n                        1/1       Running   0          14m\r\n",
      "kube-system   kube-proxy-k8t2c                        1/1       Running   0          2h\r\n",
      "kube-system   kube-svc-redirect-gr6ks                 1/1       Running   0          14m\r\n",
      "kube-system   kube-svc-redirect-ldxlv                 1/1       Running   0          51m\r\n",
      "kube-system   kube-svc-redirect-z6ppp                 1/1       Running   0          2h\r\n",
      "kube-system   kubernetes-dashboard-546f987686-8krxm   1/1       Running   2          2h\r\n",
      "kube-system   tunnelfront-695bcbdc68-t4l8t            1/1       Running   0          2h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods --all-namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{- Finished ..\n",
      "  \"agentPoolProfiles\": [\n",
      "    {\n",
      "      \"count\": 1,\n",
      "      \"dnsPrefix\": null,\n",
      "      \"fqdn\": null,\n",
      "      \"name\": \"nodepool1\",\n",
      "      \"osDiskSizeGb\": null,\n",
      "      \"osType\": \"Linux\",\n",
      "      \"ports\": null,\n",
      "      \"storageProfile\": \"ManagedDisks\",\n",
      "      \"vmSize\": \"Standard_NC6\",\n",
      "      \"vnetSubnetId\": null\n",
      "    }\n",
      "  ],\n",
      "  \"dnsPrefix\": \"fbAKSClust-fbaksrg-edf507\",\n",
      "  \"fqdn\": \"fbaksclust-fbaksrg-edf507-e12d7f40.hcp.eastus.azmk8s.io\",\n",
      "  \"id\": \"/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourcegroups/fbaksrg/providers/Microsoft.ContainerService/managedClusters/fbAKSClustergpu\",\n",
      "  \"kubernetesVersion\": \"1.9.6\",\n",
      "  \"linuxProfile\": {\n",
      "    \"adminUsername\": \"azureuser\",\n",
      "    \"ssh\": {\n",
      "      \"publicKeys\": [\n",
      "        {\n",
      "          \"keyData\": \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDTZYQFHNstYCR25qtvMrC6baTMS6TobaIRbgd0xOoafDy+2uBk0DMJuhGWoOcrsCnvadp5k/0K8qBRysyhlQGWb6+r8fBunThy+zpTKqdh3W8Q1y5UtKnGwwU1cqGXDOPUIXJYNPJqUKV829+MOrZjUynhHgSzDbY2ncGyoT+Farsvm01aGEdDapa+XRl4JAwtN1bb9q+Ii5y+MkpIOhLRMwATl05eNfAHmYQWtaIJZZJOHMNPswlBmLs293Wsj11vYh6/yo9S4ToEsc9Pbl5Zn6OFIu7jfzN2bM8cA3+8pru9WSthrxjJvPn8i4uTYozOdNIi09ArQ4lRT9t6rsMz\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"location\": \"eastus\",\n",
      "  \"name\": \"fbAKSClustergpu\",\n",
      "  \"provisioningState\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"fbaksrg\",\n",
      "  \"servicePrincipalProfile\": {\n",
      "    \"clientId\": \"eeba3bfe-45f9-42de-9bdb-54416b67382d\",\n",
      "    \"keyVaultSecretRef\": null,\n",
      "    \"secret\": null\n",
      "  },\n",
      "  \"tags\": null,\n",
      "  \"type\": \"Microsoft.ContainerService/ManagedClusters\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az aks scale --resource-group=$resource_group --name=$aks_name --node-count 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tear it all down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done with your cluster you can use the following two commands to destroy it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"azure-dl\" deleted\n",
      "service \"azure-dl\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f az-dl.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K - Starting ..\r",
      "\r",
      "\u001b[K - Finished ..\r",
      "\r",
      "\u001b[K\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az aks delete -n $aks_name -g $resource_group -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K - Finished ..\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az group delete --name $resource_group -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
